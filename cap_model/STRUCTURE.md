# Card Approval Prediction - Complete Folder Structure

This document shows the complete folder structure created for model development.

---

## ğŸ“ Complete Directory Tree

```
cap_model/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                          # Main project documentation
â”œâ”€â”€ ğŸ“„ QUICKSTART.md                      # Quick start guide (START HERE!)
â”œâ”€â”€ ğŸ“„ STRUCTURE.md                       # This file
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
â”œâ”€â”€ ğŸ“„ setup.py                           # Package installation
â”œâ”€â”€ ğŸ“„ .env.example                       # Environment variables template
â”œâ”€â”€ ğŸ“„ .gitignore                         # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“‚ data/                              # Data storage
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                          # Original, immutable data
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â””â”€â”€ credit_applications.csv      # Your data goes here
â”‚   â”œâ”€â”€ ğŸ“‚ processed/                    # Cleaned data (auto-generated)
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ val.csv
â”‚   â”‚   â””â”€â”€ test.csv
â”‚   â”œâ”€â”€ ğŸ“‚ features/                     # Feature engineering outputs
â”‚   â””â”€â”€ ğŸ“‚ external/                     # External datasets
â”‚
â”œâ”€â”€ ğŸ“‚ src/                               # Source code (main package)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ config/                       # Configuration files
â”‚   â”‚   â””â”€â”€ config.yaml                  # Main configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ data/                         # Data loading & processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py               # DataLoader class
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ features/                     # Feature engineering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py       # FeatureEngineer class
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/                       # Model training & evaluation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py                     # ModelTrainer class
â”‚   â”‚   â””â”€â”€ evaluate.py                  # ModelEvaluator class
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/                        # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py                   # Helper functions
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                           # Executable scripts
â”‚   â”œâ”€â”€ train.py                         # ğŸš€ Main training script
â”‚   â””â”€â”€ predict.py                       # ğŸ”® Prediction script
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                         # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb                     # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb     # Feature engineering
â”‚   â”œâ”€â”€ 03_baseline_models.ipynb         # Baseline models
â”‚   â””â”€â”€ 04_model_comparison.ipynb        # Model comparison
â”‚
â”œâ”€â”€ ğŸ“‚ models/                            # Trained models (auto-generated)
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ ğŸ“‚ baseline/                     # Baseline models
â”‚   â”œâ”€â”€ ğŸ“‚ experimental/                 # Experimental models
â”‚   â”œâ”€â”€ ğŸ“‚ production/                   # Production models
â”‚   â”œâ”€â”€ ğŸ“‚ preprocessors/                # Feature preprocessors
â”‚   â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”‚   â”œâ”€â”€ imputer_numerical.pkl
â”‚   â”‚   â”œâ”€â”€ imputer_categorical.pkl
â”‚   â”‚   â””â”€â”€ feature_names.pkl
â”‚   â””â”€â”€ ğŸ“‚ xgboost/                      # XGBoost specific
â”‚       â””â”€â”€ model.pkl
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/                           # Training outputs (auto-generated)
â”‚   â”œâ”€â”€ ğŸ“‚ figures/                      # Plots and visualizations
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”‚   â”œâ”€â”€ precision_recall_curve.png
â”‚   â”‚   â””â”€â”€ feature_importance.png
â”‚   â”œâ”€â”€ ğŸ“‚ reports/                      # Analysis reports
â”‚   â””â”€â”€ ğŸ“‚ metrics/                      # Evaluation metrics
â”‚       â””â”€â”€ metrics.csv
â”‚
â”œâ”€â”€ ğŸ“‚ experiments/                       # Experiment tracking
â”‚   â””â”€â”€ ğŸ“‚ configs/                      # Experiment configurations
â”‚       â”œâ”€â”€ baseline.yaml
â”‚       â”œâ”€â”€ xgboost.yaml
â”‚       â””â”€â”€ neural_net.yaml
â”‚
â””â”€â”€ ğŸ“‚ tests/                             # Unit and integration tests
    â””â”€â”€ ğŸ“‚ test_data/
        â””â”€â”€ test_data_loader.py          # Data loader tests
```

---

## ğŸ¯ Key Files Explained

### **Configuration**
- **`src/config/config.yaml`** - Central configuration file
  - Data paths and split ratios
  - Feature definitions
  - Model hyperparameters
  - MLflow settings
  - Training options

### **Core Modules**

#### Data (`src/data/`)
- **`data_loader.py`** - Load and split data
  - `DataLoader` class
  - `load_sample_data()` function
  - Data validation

#### Features (`src/features/`)
- **`feature_engineering.py`** - Feature preprocessing
  - `FeatureEngineer` class
  - Handle missing values
  - Create derived features
  - Encode categorical variables
  - Scale numerical features

#### Models (`src/models/`)
- **`train.py`** - Model training
  - `ModelTrainer` class
  - Cross-validation
  - Class imbalance handling
  - MLflow integration

- **`evaluate.py`** - Model evaluation
  - `ModelEvaluator` class
  - Calculate metrics
  - Generate plots
  - Classification reports

#### Utils (`src/utils/`)
- **`helpers.py`** - Utility functions
  - Config loading
  - Logging setup
  - Threshold optimization
  - Data summaries

### **Executable Scripts**

- **`scripts/train.py`** - Main training pipeline
  ```bash
  python scripts/train.py --track-mlflow
  ```
  - Loads data
  - Preprocesses features
  - Trains model
  - Evaluates performance
  - Saves artifacts

- **`scripts/predict.py`** - Make predictions
  ```bash
  python scripts/predict.py --mode single
  python scripts/predict.py --mode batch --input-file data.csv
  ```
  - Single prediction
  - Batch predictions
  - Load trained model

### **Notebooks**

- **`01_eda.ipynb`** - Explore your data
- **`02_feature_engineering.ipynb`** - Feature analysis
- **`03_baseline_models.ipynb`** - Quick model comparison
- **`04_model_comparison.ipynb`** - Advanced model selection

---

## ğŸš€ Usage Flow

### 1. **First Time Setup**
```bash
cd cap_model
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. **Train Model**
```bash
# With sample data (automatic)
python scripts/train.py --track-mlflow

# With your data
cp your_data.csv data/raw/credit_applications.csv
python scripts/train.py --track-mlflow
```

### 3. **View Results**
```bash
# MLflow UI
http://localhost:5000
```

### 4. **Make Predictions**
```bash
python scripts/predict.py --mode single
```

---

## ğŸ“¦ What Gets Generated

### During Training:
```
data/processed/
â”œâ”€â”€ train.csv
â”œâ”€â”€ val.csv
â””â”€â”€ test.csv

models/
â”œâ”€â”€ preprocessors/
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”œâ”€â”€ imputer_numerical.pkl
â”‚   â””â”€â”€ feature_names.pkl
â””â”€â”€ xgboost/
    â””â”€â”€ model.pkl

outputs/
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â””â”€â”€ feature_importance.png
â””â”€â”€ metrics/
    â””â”€â”€ metrics.csv
```

### In MLflow:
- All parameters
- All metrics
- All plots as artifacts
- Trained model

---

## ğŸ”§ Customization

### Change Model Type
Edit `src/config/config.yaml`:
```yaml
model:
  type: "xgboost"  # or logistic_regression, random_forest, lightgbm
```

### Add New Features
Edit `src/features/feature_engineering.py`:
```python
def _create_derived_features(self, df):
    # Add your feature engineering logic
    df['new_feature'] = ...
    return df
```

### Add New Model
1. Add model type in `src/models/train.py`
2. Add hyperparameters in `src/config/config.yaml`

---

## ğŸ“Š Outputs Explained

### **Confusion Matrix**
Shows true positives, false positives, true negatives, false negatives

### **ROC Curve**
Shows model's ability to discriminate between classes

### **Feature Importance**
Shows which features matter most for predictions

### **Metrics CSV**
Contains all numeric metrics for easy comparison

---

## ğŸ“ Best Practices

### âœ… Do:
- Use version control for code (Git)
- Track experiments with MLflow
- Keep data separate from code
- Write tests for critical functions
- Document your findings in notebooks

### âŒ Don't:
- Commit large data files
- Commit trained models (unless necessary)
- Hardcode passwords or API keys
- Skip data validation
- Train without tracking

---

## ğŸ› Troubleshooting

### Cannot import modules
```bash
pip install -e .
# or
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
```

### MLflow not accessible
```bash
kubectl port-forward -n recsys-training svc/recsys-training-mlflow 5000:5000
```

### Out of memory
- Reduce batch size in config
- Use smaller dataset for testing
- Close other applications

---

## ğŸ“š Documentation

- **QUICKSTART.md** - Get started in 5 minutes
- **README.md** - Comprehensive documentation
- **This file** - Structure reference

---

## âœ… Checklist

Setup:
- [ ] Virtual environment created
- [ ] Dependencies installed
- [ ] MLflow accessible
- [ ] Data placed in `data/raw/`

Development:
- [ ] Explored data with notebook
- [ ] Trained baseline model
- [ ] Compared models in MLflow
- [ ] Selected best model
- [ ] Tested predictions

Production:
- [ ] Model saved
- [ ] Documentation updated
- [ ] Tests written
- [ ] Ready for deployment

---

**You now have a complete, production-ready ML development environment!** ğŸ‰

For questions, see:
- `QUICKSTART.md` for quick tasks
- `README.md` for detailed info
- `/docs/05_MLflow_Model_Development.md` for MLflow guide
